<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      Глубокое обучение в гараже — Братство данных &middot; 
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/ru/styles.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
</head>


<body>
    <nav class="nav">
        <div class="nav-container">
            <a href="/ru/">
                <h2 class="nav-title"></h2>
            </a>
            <ul>
                <li><a href="/ru/about">О блоге</a></li>
                <li><a href="/ru/">Все посты</a></li>
            </ul>
            
                
                    
                        <a href="/posts/2016/02/15/deep-learning-in-the-garage-fellowship-of-data.html">
                            English
                        </a>
                    
                    
                    
                
            
                
            
        </div>
    </nav>
    <main>
        <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Max Strakhov
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2016-02-15 10:54:00 +0000">February 15, 2016</time>
    
  </div>

  <h1 class="post-title">Глубокое обучение в гараже — Братство данных</h1>
  <div class="post-line"></div>

  <p><center><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/intro_girl.png" width=520 alt="Пример работы системы"/></center></p>

<p>Вы тоже находите смайлы презабавнейшим феноменом?
В доисторические времена, когда я еще был школьником и только начинал постигать прелести интернета, с первых же добавленных в ICQ контактов смайлы ежедневно меня веселили: ну действительно, представьте, что ваш собеседник корчит рожу, которую шлет вам смайлом!</p>

<p>С тех пор утекло много воды, а я так и не повзрослел: все продолжаю иногда улыбаться присланным мне смайлам, представляя отправителя с глазами разного размера или дурацкой улыбкой на все лицо. Но не все так плохо, ведь с другой стороны я стал разработчиком и специалистом в анализе данных и машинном обучении! И вот, в прошлом году, мое внимание привлекла относительно новая, но интересная и будоражащая воображение технология глубокого обучения. Сотни умнейших ученых и крутейших инженеров планеты годами работали над его проблемами, и вот, наконец, обучать глубокие нейронные сети стало не сложнее &quot;классических&quot; методов, вроде обычных регрессий и деревянных ансамблей. И тут я вспомнил про смайлы!</p>

<p>Представьте, что чтобы отправить смайл, вы и вправду могли бы скорчить рожу, как бы было круто? Это отличное упражнение по глубокому обучению, решил я, и взялся за работу.</p>

<p>Тех, кто открыл пост целиком, попробую не разочаровать, и не повторять сюжетную линию бесчисленных постов в интернетах, в которых берут готовую модель из статьи, льют тонны данных в сеть и волшебным образом все получается. Я старался подойти к делу более методически, провести множество экспериментов, подробно изучить результаты и сделать разумные (ха-ха, надеюсь!) выводы. Более того, получить в результате, если не готовую для использования в реальном продакшене модель, то хотя бы концептуально способную работать в реалтайме при приложении понятных инженерных усилий.</p>

<p>Моя история -- это не волшебная сказка о том, как по мановению руки и запуску простого скрипта, получаются невероятные результаты. Эта история идущих друг за другом неудач, которые медленно но верно превозмогались долгими исследованиями современных и не очень статей и бесчисленными экспериментами.</p>

<h2>Дисклеймер</h2>

<p>Многие вопросы в этом цикле статей остались не освещены: как подбирать и менять скорость обучения, как настраивать топологии, как конкретно обрабатывать используемые наборы данных. Мне хотелось написать о проекте в целом и рассказать о принципиальных проблемах вставших передо мной и их возможных решениях, а не зарываться в детали.</p>

<p>Еще хочу заранее извиниться, за дикое количество англицизмов: в этой области русскоязычной литературы почти нет, и писал я как уж привык, хотя кое-где и старался использовать русские аналоги.</p>

<p><em>Все материалы, наборы данных, картинки и видео взяты из открытых источников и использованы исключительно в образовательных целях.</em></p>

<h2>Весла в воду!</h2>

<p>Для начала, тулчейн: я решил выбрать для себя достаточно взрослый, но при этом максимально гибкий инструментарий. Это сразу отбросило Caffe и разные хардкорные С++ библиотеки, в конце концов, это же исследовательский проект!
В принципе, (на тот момент) оставались только Theagit config credential.helper cacheno и Torch (tensorflow еще не вышел). И Python и Lua я хорошо знаю и имею довольно большой опыт с обоими языками, так что выбор был чисто вкусовой: я выбрал Theano просто потому, что он мне показался гибче, ведь он хоть и поддерживает примитивы глубокого обучения, но вообще он строит произвольные символьные выражения, и кажется более обобщенным. В качестве компенсации готовым кирпичикам-слоям, которые есть в Torch и нет в Theano, я решил использовать Lasagne, в сущности те же самые кирпичики, но поверх Theano.</p>

<p>Сразу скажу, что выбирал я не достаточно осведомленно, а именно, не имея еще никакого опыта с сетями, так что в процессе я много раз пожалел и разжалел назад, что не выбрал Torch. В итоге, до сих пор не определился, что лучше :)</p>

<p>Итак, выбрали платформу, можно кодить! Но что?</p>

<h2>Задача</h2>

<p>Продуктово все более или менее понятно: я хочу отправлять смайлы не выбирая их из списка, а, изображая их на лице. Итого, я хочу корчить рожу, фотографироваться, и система, в идеале, за меня должна понять, какой смайл я изображаю и вписать его в сообщение. <em>Сразу разочарую: до прототипа в виде плагина к скайпу, вотсапу или хэнгауту так и не дошло (пока?), не хватает времени, доделал я только систему из сетей.</em></p>

<p>По счастью, такие продуктовые требования легко преобразовать в технологические: нам нужно, простыми словами, уметь преобразовывать селфи в смайл!</p>

<p>Для того, чтобы преобразовывать лицо в смайл, его нужно сначала найти и выделить (мы же не хотим заставлять пользователя выравнивать лицо в экране, правда?).</p>

<p>Итак, алгоритм:</p>

<ol>
<li>Ищем лицо.</li>
<li>Вырезаем.</li>
<li>Преобразовываем в смайл.</li>
<li>??????</li>
<li>PROFIT!</li>
</ol>

<h2>Все, можно учить!</h2>

<p>Только чему? Сначала разберемся с детекцией лиц. Интернеты пестрят статьями про классификацию изображений. Но нам, первым делом, нужна не классификация, а детекция! И это гораздо сложнее. К счастью, тут появляется первый важный инсайт: детекцию можно свести к классификации. Давайте возьмем нашу сеть, и применим ее не ко всему изображению, а ко всем квадратным окнам внутри этого изображения. А точнее, не ко всем, а к окнам нескольких размеров со смещением
<center><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/formula1.gif" width="520"></center></p>

<p>Получается алгоритм (полупсевдокод):</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">windows</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">window_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>
    <span class="k">while</span> <span class="n">not_too_small</span><span class="p">(</span><span class="n">window_size</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">y</span> <span class="o">&lt;</span> <span class="n">img</span><span class="o">.</span><span class="n">height</span><span class="p">:</span>
            <span class="k">while</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">img</span><span class="o">.</span><span class="n">width</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="n">dx</span>
            <span class="k">if</span> <span class="n">pixels_x_left_unyilded</span><span class="p">():</span>
                <span class="k">yield</span> <span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">width</span> <span class="o">-</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">+=</span> <span class="n">dy</span>
        <span class="k">if</span> <span class="n">pixels_y_left_unyilded</span><span class="p">():</span>
            <span class="k">while</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">img</span><span class="o">.</span><span class="n">width</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">hight</span> <span class="o">-</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">x</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">hight</span> <span class="o">+</span> <span class="n">window_size</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">+=</span> <span class="n">dx</span>
        <span class="n">window_size</span> <span class="o">/=</span> <span class="n">resizing_factor</span>
        <span class="n">dx</span> <span class="o">/=</span> <span class="n">resizing_factor</span>
        <span class="n">dy</span> <span class="o">/=</span> <span class="n">resizing_factor</span>
</code></pre></div>
<p><br/>
Итого, мы ресайзим изображение в несколько разных масштабов и для каждого масштаба ездим окном фиксированного размера с шагом в 4 пикселя. И выполняем классификацию каждого квадрата лицо/не лицо. После этого у нас, конечно, получится много квадратов, загоревшихся для каждого лица, так что их надо будет как-то слить. Алгоритмы можно придумывать разные, умные и не очень, но я просто выбираю лучший загоревшийся квадрат среди сильно пересекающихся:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">filter_frames</span><span class="p">(</span><span class="n">frames</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">frames</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">frames</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="n">probability_of_face</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">frames</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="n">frames</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">frames</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">intersection</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">f</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">big_enough</span><span class="p">:</span>
                <span class="n">frames</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div>
<h2>Таки учим?</h2>

<p>А что? По счастливой отнюдь не случайности я уже заранее вооружился знаниями из нескольких текстовых и видео курсов по глубокому обучению, нескольких интересных блогов и достаточно большого набора прочтенных статей по современным исследованиям (большим по меркам месяца, на тот момент, подготовки, но тем не менее, мне хватило).</p>

<p>Если хотим работать с изображениями -- используем конволюционные сети. No exceptions.</p>

<p>На самом деле, есть и другое мнение от великих умов на этом поприще: правильно использовать обычные слои, а конволюции -- от лукавого. Ведь, по сути, они являют собой не что иное как обычные же слои, но с &quot;захардкоженным&quot; свойством независимости от положения объекта. Но это свойство, во-первых, можно было бы и выучить самой сетью, а во-вторых, оно вообще не корректно, ведь во время детекции положение нам как раз важно!</p>

<p>Плохой новостью для такого подхода является неспособность его осуществления на современном железе, так что откладываем этот вариант на десяток лет и делаем конволюционные сети.</p>

<p>И тут нам очень везет, ведь это довольно просто! По примеру первого эпического прорыва CNN -- AlexNet, архитектуру которого повторить довольно просто: бери себе конволюционно-пулинговых слоев, сколько можешь позволить, а сверху парочку полносвязных. Чем больше сеть, тем лучше, за исключением того, что она очень легко переобучается, но, слава Хинтону, с этим очень легко справиться с помощью техники под названием dropout и небольшого затухания весов на всякий случай.</p>

<p><center><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/schema-alexnet.png" width=600 alt="AlexNet"/></center></p>

<p>Моя первая, еще маленькая, сеть:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">build_net12</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="n">input_var</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nonlin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">nonlin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nonlin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">network</span>
</code></pre></div>
<p><br/>
Маленькая она в основном потому, что на тот момент у меня еще не было доступных GPU и я оптимизировал на CPU, что очень медленно.</p>

<h2>Ну учим уже наконец?</h2>

<p>А на чем? К счастью, добрые люди создали множество открытых датасетов для задач распознавания и детекции лиц. Я первым делом взял датасет под названием FFDB. В нем достаточно много фотографий, на которых лица выделены эллипсами (не прямо поверх фоток, а отдельно выписаны параметры эллипса в текстовом файле). Этот датасет можно использовать только в образовательных целях, но у нас ведь именно такие цели, правда? :) Дополнительно, я туда добросил немного данных, размеченных мной самим и полученных с фотографий, аналогичных КПДВ.</p>

<h2>Все есть, пошли учить!</h2>

<p>Пошли. И сразу, волшебным образом, получилось!</p>

<p><center>
<img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_1_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_1_accuracy.png" width=340 height=264 alt="Точность"/></center>
<center><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_1_example.png" height=264 alt="Пример детекции"/></center></p>

<p><i>Скриншоты сделаны в специально разработанной мной системе мониторинга обучения нейронных сетей под названием DeepEvent, о которой я напишу в отдельной статье, если будет интерес.</i></p>

<p>Первые 10 итераций обучения обрезаны просто потому, что они мало что говорят и сильно зависят от случайной инициализации весов.
В примере работы красным отмечены все окна, в которых сеть нашла лицо, зеленым отмечены окна, оставшиеся после фильтрации.
<i>Еще признаюсь, что тут есть небольшой обман: все графики были сделаны сильно позже не на тех самых экспериментах, а на чуть более продвинутых и где надо починенных, но аналогичных. Дело в том, что DeepEvent был разработан совсем не сразу и результаты первых экспериментов утеряны навечно. Хотя, как сейчас помню, вот эта сеть в самом начале давала не 92%, а около 89.5%.</i></p>

<p>И тут же мы видим, что хоть сеть и показывает заоблачные для таких малых усилий со стороны меня 92%, настоящее качество детекции оставляет желать лучшего. Что делать? Надо учить сеть побольше!</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">build_net48</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">48</span><span class="p">),</span> <span class="n">input_var</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">,</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">,</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">network</span>
</code></pre></div>
<p><br/>
И ничего не выходит. Оказывается, что часто забывают рассказать в статьях, для глубокого обучения нужно много данных. Очень много. С вышеописанным датасетом у меня вышло достойно обучить небольшую модель, но небольшая модель не давала качества, которого хотелось. Большая же модель никак не сходилась в нормальные минимумы, а если уменьшать пороги дропаута, быстро переобучалась, что логично: большой модели не составляет труда просто запомнить небольшой объем обучающих данных.</p>

<h2>Аугментация</h2>

<p>Ну хорошо, рассудил я, нам надо больше данных -- сделаем больше данных! И реализовал процесс, который, как я впоследствии узнал, называется аугментация данных: это когда к исходным данным применяются преобразования, что эффективно увеличивает размер обучающей выборки в сотни, а то и тысячи раз.</p>

<p>Итак, для каждого примера с вероятностью 0.5 отражаем его по горизонтали, ведь от этого не меняется класс лицо/не лицо. Так же, каждый для каждого лица я взял не исходный квадрат, полученный из эллипса, присутствовавшего в датасете, а квадрат во-первых случайно слегка увеличенный (или уменьшенный) в некотором интервале, а во-вторых, после этого случайно слегка сдвинутый по x и y в некоторых интервалах.
Дополнительно, позже я еще придумал брать не сам этот квадрат, а его, но случайно слегка растянутого либо по x либо по y (50/50). В результате чего получается вырезанный из картинки прямоугольник с лицом, который потом надо превратить в квадрат сжатием. Отличие этого преобразования в том, что предыдущее изменяет размеры и положение квадрата но не деформирует само лицо, а это преобразование деформирует лицо: слегка растягивает/сжимает его либо по вертикали либо по горизонтали.</p>

<p>Псевдокод аугментации:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">get_rnd_img_frame</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">box</span><span class="p">,</span> <span class="n">net_input_size</span><span class="p">):</span>
    <span class="n">box</span> <span class="o">=</span> <span class="n">move_box</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">random</span><span class="p">(</span><span class="n">minx</span><span class="p">,</span> <span class="n">maxx</span><span class="p">),</span> <span class="n">random</span><span class="p">(</span><span class="n">miny</span><span class="p">,</span> <span class="n">maxy</span><span class="p">))</span>
    <span class="n">box</span> <span class="o">=</span> <span class="n">scale_box</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">random</span><span class="p">(</span><span class="n">minscale</span><span class="p">,</span> <span class="n">maxscale</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">stretch_x</span><span class="p">,</span> <span class="n">stretch_y</span> <span class="o">=</span> <span class="n">random</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">stretchx</span><span class="p">),</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">stretch_x</span><span class="p">,</span> <span class="n">stretch_y</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">random</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">stretchy</span><span class="p">)</span>
    <span class="n">box</span> <span class="o">=</span> <span class="n">stretch_box</span><span class="p">(</span><span class="n">box</span><span class="p">,</span> <span class="n">stretch_x</span><span class="p">,</span> <span class="n">stretch_y</span><span class="p">)</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">box</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">mirror</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">frame</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">net_input_size</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">net_input_size</span><span class="o">.</span><span class="n">y</span><span class="p">))</span>
</code></pre></div>
<p><br/>
С помощью вышеописанных комбинаций, я получил эффективно бесконечный набор данных: вероятность повтора картинки за 500 эпох обучения по моим прикидкам была где-то в районе десятой доли процента для моего размера картинок.</p>

<p>Вот результаты той же маленькой модели, но с дополненными обучающим и тестовым множествами:</p>

<p><center>
<img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_2_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_2_accuracy.png" width=340 height=264 alt="Точность"/></center>
<center><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_2_example.png" height=264 alt="Пример детекции"/></center></p>

<p>На примере работы теперь есть еще синие квадраты, из за того, что я разделил фильтрацию на две стадии: сначала фильтруются только окна каждого размера в отдельности, выбирая лучшие среди своего размера (синие), и глобально среди всех размеров (зеленые), заодно, почему-то я уменьшил шаг скольжения окна.</p>

<h2>Оптимизация I</h2>

<p>Правда, взамен малому объему обучающих данных я получил другую проблему: для потенциально бесконечного объема данных нужен потенциально бесконечно мощный компьютер! Или умный трюк. Так как я больше специализируюсь по софтварной части, я решил, что потенциально бесконечно мощный компьютер я построю в следующий раз, а текущую проблему решу умным трюком: не буду заранее генерировать датасет для обучения и грузить его целиком в память, а построю заранее некий индекс с исходным недополненным датасетом, который я буду дополнять прямо в рантайме. В сущности, прямо во время итерации для каждого объекта в минибатче я вызываю вышеприведенный алгоритм и получаю дополненные данные, сгенерированные на лету.</p>

<p>С этим, кстати, связана забавная история. Когда я отладил все это на CPU и пошел запускать на GPU я увидел бешеную просадку производительности: сами посудите, алгоритм аугментации содержит кучу логики, после которой идет еще и отражение и ресайз картинки! И так для всех 1024 элементов минибатча, умножить на несколько десятков минибатчей на итерацию!</p>

<p>В общем, понятное дело, меня это категорически не устроило, и я пошел разбираться. И оказалось, что все вполне логично: в однопоточной python-программе GPU просто-напросто спит, пока CPU не спеша генерирует минибатч. Лень -- это плохо, с ней надо бороться и я решил, что GPU должно впахивать, аки раб на галерах, каждое доступное мне мгновение!</p>

<p>Решение? Не блокировать GPU! Давайте, CPU будет асинхронно готовить следующий батч, пока GPU учит сеть на текущем. Так я и сделал. И я был абсолютно уверен в успехе этой операции, но меня ждало разочарование: это почти не помогло. Оказалось, что CPU работает гораздо дольше, чем GPU, особенно на небольших сетях, и GPU все равно спит большую часть времени.</p>

<p>Ну что ж, зря что ли я проектировал все эти веб-сервисы? Как оптимизировать параллельную примерно одинаковую read-only обработку большого массива объектов? Шардинг (оно же MapReduce)! Давайте, решил я, запустим много процессов и каждому выдадим кусочек минибатча, который они будут обрабатывать, складывать результаты в очередь и тут же, не ожидая, обрабатывать кусок следующего минибатча, если очередь не переполнена. Дополнительно, запустим еще один процесс, который будет слушать эту очередь, понимать, к какому минибатчу относится кусок, собирать из кусков минибатч и складывать его во вторую очередь, из которой уже забирает данные основной процесс, работающий с GPU.</p>

<p>И, наконец, вооружившись сервером с 32 вычислительными ядрами и запустив генерацию дополненных данных в 32 процесса (+ два почти всегда ждущих на очереди или GPU) и загрузив его по самое не хочу, начиная со второй эпохи GPU почти перестало спать.</p>

<h2>Ура, учим!</h2>

<p>Итак, теперь можно научить уже не игрушечную модель нормальных размеров и, успех!, при правильной настройке она не переобучается и не болтается вне минимумов.</p>

<p><center><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_3_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_3_accuracy.png" width=340 height=264 alt="Точность"/></center>
<center><img src="/images/posts/2016-02-15-deep-learning-in-the-garage-fellowship-of-data/train_3_example.png" height=264 alt="Пример детекции"/></center></p>

<p>Здесь явно видно, как появляются стремные всплески в процессе обучения (почему -- будет дальше), но в итоге все становится более или менее хорошо, хотя все-таки слегка болтуче.</p>

<p><em>В следующих сериях:
Еще больше данных, еще больше сетей, калибрация, поражающие воображение ансамбли сетей, современные технологии, больше картинок, девочек и драмы!</em></p>

<h2>Благодарности</h2>

<p>Спасибо <a href="https://github.com/andrewtar">Андрею Тарашкевичу</a> за помощь с версткой этой статьи в Jekyll.</p>


</div>

<div class="pagination">
  
    <a href="/ru/posts/2016/02/16/deep-learning-in-the-garage-two-nets.html" class="left arrow">&#8592;</a>
  
  

  <a href="#" class="top">Top</a>
</div>

    </main>
    <footer>
        <span>
            &copy; <time datetime="2018-10-27 19:30:09 +0000">2018</time> You can find me on <a href="https://github.com/Monnoroch">GitHub</a>.
        </span>
    </footer>
    <script src="/scripts/responsive.js" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']]
            }
        });
    </script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
