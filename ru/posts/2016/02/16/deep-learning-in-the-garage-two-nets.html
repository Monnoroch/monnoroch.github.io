<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      Глубокое обучение в гараже — Две сети &middot; 
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/ru/styles.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
</head>


<body>
    <nav class="nav">
        <div class="nav-container">
            <a href="/ru/">
                <h2 class="nav-title"></h2>
            </a>
            <ul>
                <li><a href="/ru/about">О блоге</a></li>
                <li><a href="/ru/">Все посты</a></li>
            </ul>
            
                
                    
                        <a href="/posts/2016/02/16/deep-learning-in-the-garage-two-nets.html">
                            English
                        </a>
                    
                    
                    
                
            
                
            
        </div>
    </nav>
    <main>
        <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Max Strakhov
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2016-02-16 13:03:00 +0000">February 16, 2016</time>
    
  </div>

  <h1 class="post-title">Глубокое обучение в гараже — Две сети</h1>
  <div class="post-line"></div>

  <p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/intro-girl.png" width=520 alt="Пример работы системы"/></center></p>

<h2>Калибрация</h2>

<p>Итак, с классификатором, разобрались, но вы наверняка уже заметили, что заоблачные 99% как-то не очень впечатляюще выглядят во время боевого теста на детекцию. Вот и я заметил. Дополнительно видно, что в последних двух примерах очень мелкий шаг движения окон, так в жизни работать не будет. В настоящем, реальном запуске шаг ожидается больше похожим на картинку для первой сети, а там хорошо видно неприятный факт: как бы хорошо сеть не искала лица, окна будут плохо выровнены к лицам. И уменьшение шага -- явно не подходящее решение этой проблемы для продакшена.</p>

<p>Ну хорошо, подумал я. Мы нашли окна, но нашли не точные окна, а как бы смещенные. Как бы так их сместить &quot;назад&quot;, чтобы лицо оказалось в центре? Естественно, автоматически. Ну, и раз уж я занялся сетями, то и &quot;восстанавливать&quot; окна я решил тоже сетью. Но как?</p>

<p>Первой мыслью пришло предсказывать сетью три числа: на сколько пикселей надо сместить по x и y и в какую константу раз увеличить (уменьшить) окно. Получается, регрессия. Но тут я сразу почувствовал, что что-то не так, аж три регрессии надо сделать! Да еще две из них дискретные. Да еще и ограничены шагом движения окна по оригинальному изображению, ведь нет смысла сдвигать окно далеко: там было другое окно! Последним гвоздем в гробу этой идеи оказались пара независимых статей, которые утверждали, что регрессия сильно хуже классификации решается современными сетевыми методами, и что она гораздо менее стабильна.</p>

<p>Так что, решено было свести задачу регрессии к задаче классификации, что оказалось более чем возможно, учитывая, что окно мне надо подергать совсем немного. Для этих целей, собрал датасет, в котором брал выделенные лица из оригинального датасета, смещал их в девять (включая никакую) разных сторон и увеличивал/уменьшал в пять разных коэффициентов (включая единицу). Итого, получил 45 классов.</p>

<p>Проницательный читатель тут должен ужаснуться: классы-то получились очень сильно связанными друг с другом! Результат такой классификации может вообще мало иметь отношения к реальности.</p>

<p>Для успокоения внутреннего математика я привел три довода:</p>

<ol>
<li>По сути, обучение сети -- это просто поиск минимума функции потерь. Не обязательно его интерпретировать, как классификацию.</li>
<li>Мы же ничего и не классифицируем, на самом-то деле, мы эмулируем регрессию! В совокупности с осознанием первого пункта, это позволяет не фокусироваться на формальной корректности.</li>
<li>Это, черт возьми, работает!ыл бы базис, если</li>
</ol>

<p>Так как мы не классифицируем, а эмулируем регрессию, то нельзя просто взять лучший класс и считать, что он верный. Поэтому я беру распределение классов, которое выдает сеть для каждого окна, удаляю совсем уж маловероятные (&lt; 2.2%, что равно 1/45, что значит, что вероятность меньше случайной), и для оставшихся классов суммирую их смещения с вероятностями в качестве коэффициентов и получаю как бы регрессию в таком небольшом небазисе <em>(был бы базис, если бы классы были независимы, а так ну никак не базис же :)</em>.
Итого, я ввел в систему вторую сеть, калибрационную. Она выдавала распределение по классам, на основе которого я калибровал окна, надеясь, что лица будут выравниваться по центру окон.</p>

<p>Давайте попробуем обучить вот такую сеть:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">build_net12_cal</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="n">input_var</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">nolin</span><span class="o">=</span><span class="n">linear</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">network</span>
</code></pre></div>
<p><br/>
И вот такой алгоритм расчета смещения:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">get_calibration</span><span class="p">():</span>
    <span class="c1"># ds -- это изменение scale</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">dx1</span><span class="p">,</span> <span class="n">dy1</span><span class="p">,</span> <span class="n">ds1</span><span class="p">),</span> <span class="p">(</span><span class="n">dx2</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">ds2</span><span class="p">),</span> <span class="o">...</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
    <span class="n">min_cal_prob</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
    <span class="c1"># вернет вероятности калибрационных классов для каждого окна, обрезанные по нижнему порогу</span>
    <span class="n">cals</span> <span class="o">=</span> <span class="n">calibration_net</span><span class="p">(</span><span class="o">*</span><span class="n">frames</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">min_cal_prob</span>
    <span class="c1"># первая сумма -- по всем окнам, вторая сумма -- по классам для каждого окна.</span>
    <span class="c1"># Она была бы всегда равна единице, если бы не было отсечения строкой выше</span>
    <span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">ds</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">classes</span> <span class="o">*</span> <span class="n">cals</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">cals</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">ds</span>
</code></pre></div>
<p><br/>
И это работает!</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/picture_calibration.png" height=320 alt="Калибрация"/></center></p>

<p>Слева исходные окна от детекционной сети (маленькой), справа они же, но откалиброванные. Видно, что окна начинают группироваться в явные кластера. Дополнительно, это помогает более эффективно фильтровать дубликаты, так как окна, относящиеся к одному лицу, пересекаются большей площадью и становится легче понять, что одно из них надо отфильтровать. Так же это позволяет уменьшить число окон в продакшене за счет увеличения шага скольжения окна по изображению.</p>

<p>Заодно вот и результаты обучения маленькой калибрации:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_small_calibration_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_small_calibration_accuracy.png" width=340 height=264 alt="Точность"/></center></p>

<p>и большой калибрации:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_big_calibration_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_big_calibration_accuracy.png" width=340 height=264 alt="Точность"/></center></p>

<p>а вот и сама большая калибрационная сеть:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">build_net48_cal</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">48</span><span class="p">),</span> <span class="n">input_var</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">3</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">3</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">nolin</span><span class="o">=</span><span class="n">linear</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">network</span>
</code></pre></div>
<p><br/>
К этим графикам стоит относиться скептически, ведь нам нужна не классификация, а регрессия. Но эмпирическое тестирование взглядом показывает, что калибрация, обученная таким образом, хорошо выполняет свою цель.
Еще замечу, что для калибрации исходный набор данных в 45 раз больше, чем для классификации (по 45 классов для каждого лица), но с другой стороны, его нельзя было дополнить вышеописанным образом просто по постановке задачи. Так что, колбасит, особенно большую сеть, изрядно.</p>

<h2>Оптимизация II</h2>

<p>Вернемся к детекции. Эксперименты показали, что маленькая сеть не дает нужного качества, так что нужно обязательно учить большую. Но проблема большой в том, что даже на мощной GPU очень долго классифицировать тысячи окон, которые получаются из одной фотографии. Такую систему было бы просто невозможно воплотить в жизнь. В текущем варианте есть большой потенциал для оптимизаций хитрыми трюками, но я решил, что они не достаточно масштабируемы и проблему надо решать качественно, а не хитро оптимизируя флопсы. И решение же вот оно, перед глазами! Маленькая сеть со входом 12х12, одной конволюцией, одним пулингом и классификатором сверху! Она работает очень быстро, особенно учитывая, что запустить классификацию на GPU можно параллельно для всех окон -- получается почти мгновенно.</p>

<h2>Ансамбль</h2>

<p><em>One Ensemble to bring them all and in the darkness bind them.</em></p>

<p>Итак, было решено использовать не одну классификацию и одну калибрацию, а целый ансамбль сетей. Сначала будет идти слабая классификация, потом слабая же калибрация, потом фильтрация откалиброванных окон, которые предположительно указывают на одно лицо, а потом уже только на этих оставшихся окнах прогонять сильную классификацию и затем сильную калибрацию.</p>

<p>Позже, практика показала, что это все еще довольно медленно, так что я сделал ансамбль аж из трех уровней: в середине между этими двумя была вставлена &quot;средняя&quot; классификация, за которой шла &quot;средняя&quot; калибрация и потом фильтрация. В такой комбинации система работает достаточно быстро, что есть реальная возможность использовать ее в продакшене, если приложить некоторые инженерные усилия и реализовать некоторые трюки, просто, чтобы уменьшить флопсы и увеличить параллельность.</p>

<p>Итого получаем алгоритм:</p>

<ol>
<li>Находим все окна.</li>
<li>Проверяем первой детекционной сетью.</li>
<li>Те, что загорелись, калибруем первой калибровочной сетью.</li>
<li>Фильтруем пересекающиеся окна.</li>
<li>Проверяем второй детекционной сетью.</li>
<li>Те, что загорелись, калибруем второй калибровочной сетью.</li>
<li>Фильтруем пересекающиеся окна.</li>
<li>Проверяем третьей детекционной сетью.</li>
<li>Те, что загорелись, калибруем третьей калибровочной сетью.</li>
<li>Фильтруем пересекающиеся окна.</li>
</ol>

<h2>Батчи окон</h2>

<p>Если шаги со второго по седьмой делать для каждого окна отдельно, получается довольно долго: постоянные переключения с CPU на GPU, неполноценная утилизация параллелизма на видеокарте и кто знает что еще. Поэтому было решено сделать конвейеризованную логику, которая бы могла работать не только с отдельными окнами, а  с батчами произвольного размера. Для этого было решено каждую стадию превратить в генератор, и между каждой стадией поставить код, который тоже работает как генератор, но не окон, а батчей и буферизирует результаты предыдущей стадии и при накоплении заранее заданного числа результатов (или конце) отдает собранный батч дальше.</p>

<p>Эта система неплохо (процентов на 30) ускорила обработку во время детекции.</p>

<h2>Moar data!</h2>

<p>Как выше я уже заметил в предыдущей статье, большая детекционная сеть учится со скрипом: постоянные резкие прыжки, да и болтает ее. И дело не в скорости обучения, как бы в первую очередь подумал любой, знакомый с обучением сетей! Дело в том, что все-таки мало данных. Проблема обозначена -- можно искать решение! И оно тут же нашлось: датасет Labeled Faces in the Wild.</p>

<p>Объединенный датасет из FDDB, LFW и моих личных доливок стал почти втрое больше исходного. Что из этого получилось? Меньше слов, больше картинок!</p>

<p>Маленькая сеть заметно стабильней, быстрее сходится и результат лучше:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_small_net_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_small_net_accuracy.png" width=340 height=264 alt="Точность"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_small_net_example.png" height=264 alt="Пример детекции"/></center></p>

<p>Большая сеть тоже заметно стабильней, пропали всплески, сходится быстрее, результат, внезапно, чуток хуже, но 0.17% кажутся мне допустимой погрешностью:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_big_net_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_big_net_accuracy.png" width=340 height=264 alt="Точность"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_big_net_example.png" height=264 alt="Пример детекции"/></center></p>

<p>Дополнительно, такое увеличение объема данных позволило еще увеличить большую модель для детекции:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_big_net_more_data_losses.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_big_net_more_data_accuracy.png" width=340 height=264 alt="Точность"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/train_big_net_more_data_example.png" height=264 alt="Пример детекции"/></center></p>

<p>Видим, что модель еще быстрее сходится, к еще лучшему результату и очень стабильно.</p>

<p>Заодно я заново обучил и калибрационные сети на большем объеме данных.</p>

<p>Маленькая калибрация:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_small_calibration_losses_2.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_small_calibration_accuracy_2.png" width=340 height=264 alt="Точность"/></center></p>

<p>и большая калибрация:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_big_calibration_losses_2.png" width=340 height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_big_calibration_accuracy_2.png" width=340 height=264 alt="Точность"/></center></p>

<p>В отличии от детекционной сети тут видно прямо-таки драматическое улучшение. Это происходит потому, что исходная обучающая выборка не аугментируется и исходная сеть сильно страдает от недостатка данных, как страдала сеть для детекции до аугментации.</p>

<h2>Детектирование готово</h2>

<p>Картинка, иллюстрирующая весь пайплайн (классификация-1, калибрация-1, фильтрация, классификация-2, калибрация-2, фильтрация, классификация-3, калибрация-3, фильтрация, глобальная фильтрация, белым отмечены лица из тренировочного множества):</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/pipeline_example.png" height=800 alt="image"/></center></p>

<p>Успех!</p>

<h2>Мультиразрешение</h2>

<p>К этому моменту те из вас, кто следит за трендами, наверняка уже подумали, мол что за динозавр, использует техники из глубокой древности (4 года назад :), где же свежие крутые приемы? А вот они!</p>

<p>На просторах arxiv.org была подчерпнута интересная идея: а давайте карты фичей в конволюционных слоях считать на разных разрешениях: банально сделать сети несколько входов: NxN, (N/2)x(N/2), (N/4)x(N/4), сколько угодно! И подавать один и тот же квадрат, только по-разному уменьшенный.
Потом же для финального классификатора все карты конкатенируются и он как бы может смотреть на разные разрешения.</p>

<p>Слева было, справа стало (померяно на той самой средней сети):
<center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_multidimensional_losses.png" height=264 alt="image"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/graph_multidimensional_accuracy.png" height=264 alt="image"/></center></p>

<p>Видно, что в моем случае сеть с несколькими разрешениями сходится быстрее и чуть менее болтается. Тем не менее, идею я отбросил, как не работающую, так как маленькая и средняя сети не должны быть суперточными, а большую вместо мультиразрешений я просто потом увеличил с еще большим успехом.</p>

<h2>Batch normalization</h2>

<p>Batch normalization -- это техника регуляризации сети. Идея в том, что каждый слой на вход принимает результат предыдущего слоя, в котором может быть практически любой тензор, координаты которого предположительно как-то распределены. А слою было бы очень удобно, если бы на вход ему подавали тензоры с координатами из фиксированного распределения, одного для всех слоев, тогда ему не нужно было бы учить преобразование инвариантное к параметрам распределения входных данных. Ну и окей, давайте между всеми слоями вставим некое вычисление, которое оптимальным образом нормализует выходы предыдущего слоя, что снижает давление на следующий слой и дает ему возможность делать свою работу лучше.</p>

<p>Мне эта техника неплохо помогла: она позволила снизить вероятность дропаута при сохранении того же качества модели. Снижение вероятности дропаута в свою очередь приводит к ускорению сходимости сети (и большему переобучению, если делать это без нормализации батчей). Собственно, буквально на всех графиках вы видите результат: сети достаточно быстро сходятся к 90% финального качества. До нормализации батчей падение ошибки было существенно более пологим (к сожалению результаты не сохранились, так как тогда еще не было DeepEvent).</p>

<h2>Inceptron</h2>

<p>Разумеется, я не смог устоять перед тем, чтобы поковыряться с современными архитектурами и попробовал натренировать на классификацию лиц Inceptron (не GoogLeNet, а гораздо меньшую сеть). К сожалению, в Theano эту модель правильно сделать нельзя: библиотека не поддерживает zero-padding произвольного размера, так что мне пришлось оторвать одну из веток Inception-модуля, а именно правую на этой картинке:</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/schema-inception-module.png" width=480 alt="Inception module"/></center></p>

<p>Дополнительно, у меня было лишь три inception-модуля друг на друге, а не семь, как в GoogLeNet, не было предварительных выходов, и не было обычных конволюционно-пулинговых слоев в начале.</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">build_net64_inceptron</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">input_var</span><span class="o">=</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">b1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ConcatLayer</span><span class="p">([</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">b1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ConcatLayer</span><span class="p">([</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">b1</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">104</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ConcatLayer</span><span class="p">([</span><span class="n">b1</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span> <span class="n">b3</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">network</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">nolin</span><span class="o">=</span><span class="n">relu</span><span class="p">)</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">DenseLayer</span><span class="p">(</span><span class="n">lasagne</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">p</span><span class="o">=.</span><span class="mi">5</span><span class="p">),</span> <span class="n">num_units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nolin</span><span class="o">=</span><span class="n">linear</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">network</span>
</code></pre></div>
<p><br/>
И у меня даже получилось!</p>

<p><center><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/result_losses.png" height=264 alt="Ошибка"/><img src="/images/posts/2016-02-16-deep-learning-in-the-garage-two-nets/result_accuracy.png" height=264 alt="Точность"/></center></p>

<p>Результат на процент хуже обычной конволюционной сети, обученной мной ранее, но тоже достойный! Однако, когда я попробовал обучить такую же сеть, но из четырех inception-модулей, она стабильно разлеталась. У меня осталось ощущение, что эта архитектура (как минимум, с моими модификациями) очень капризная. К тому же, batch normalization, почему-то, стабильно превращала эту сеть в полный расколбас. Тут я подозреваю полукустарную реализацию batch normalization для Lasagne, но в общем все это заставило меня отложить Инцептрон до светлого будущего с Tensorflow.</p>

<h2>Кстати, Tensorflow!</h2>

<p>Конечно, я попробовал и его! Эту модную технологию я опробовал в тот же день, когда он вышел с большими надеждами и восхищением Гуглом, спасителем нашим! Но нет, надежд он не оправдал. Заявленного автоматического использования нескольких GPU нет и в помине: на разные карточки нужно руками помещать операции; работал он только с последней кудой, которую мне тогда было нельзя ставить на сервер, имел захардкоженную версию libc и не пускался на другом сервере, да еще и собирался вручную с помощью blaze, который не работает в докер-контейнерах. Короче, одни разочарования, хотя сама модель работы с ним очень даже неплоха!</p>

<p>Tensorboard тоже оказался разочарованием. Не хочу вдаваться в детали, но мне все не нравилось и я занялся разработкой своего мониторинга под названием DeepEvent, скриншоты с которого вы видели в статье.</p>

<p><em>В следующей серии:
Смайлы, готовая система, результаты и, наконец-то уже, симпатичные девушки!</em></p>

<h2>Благодарности</h2>

<p>Спасибо <a href="https://github.com/andrewtar">Андрею Тарашкевичу</a> за помощь с версткой этой статьи в Jekyll.</p>


</div>

<div class="pagination">
  
    <a href="/ru/posts/2016/02/17/deep-learning-in-the-garage-return-of-smiles.html" class="left arrow">&#8592;</a>
  
  
    <a href="/ru/posts/2016/02/15/deep-learning-in-the-garage-fellowship-of-data.html" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>
    <footer>
        <span>
            &copy; <time datetime="2018-10-27 19:30:09 +0000">2018</time> You can find me on <a href="https://github.com/Monnoroch">GitHub</a>.
        </span>
    </footer>
    <script src="/scripts/responsive.js" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']]
            }
        });
    </script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
