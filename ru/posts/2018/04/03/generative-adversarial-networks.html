<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      Generative adversarial networks &middot; 
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/ru/styles.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
</head>


<body>
    <nav class="nav">
        <div class="nav-container">
            <a href="/ru/">
                <h2 class="nav-title"></h2>
            </a>
            <ul>
                <li><a href="/ru/about">О блоге</a></li>
                <li><a href="/ru/">Все посты</a></li>
            </ul>
            
                
                    
                        <a href="/posts/2018/04/03/generative-adversarial-networks.html">
                            English
                        </a>
                    
                    
                    
                
            
                
            
        </div>
    </nav>
    <main>
        <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Max Strakhov
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2018-04-03 09:00:00 +0000">April 03, 2018</time>
    
  </div>

  <h1 class="post-title">Generative adversarial networks</h1>
  <div class="post-line"></div>

  <p>В <a href="/ru/posts/2018/02/05/generative-modeling-and-ai.html">прошлой статье</a> мы рассмотрели порстейшую линейную генеративную модель PPCA. Вторая генеративная модель, которую мы рассмотрим &mdash; Generative Adversarial Networks, сокращенно GAN. В этой статье мы рассмотрим самую базовую версию этой модели, оставив продвинутые версии и сравнение с другими подходами в генеративном моделировании на следующие главы.</p>

<p><center><img src="/images/posts/2018-04-03-generative-adversarial-networks/intro.gif" width="520"/></center></p>

<h2>История</h2>

<p>Генеративное моделирование предполагает аппроксимацию невычислимых апостериорных распределений. Из-за этого большинство эффективных методов, разработанных для обучения дискриминативных моделей, не работают с генеративными моделями. Существующие в прошлом методы для решения этой задачи вычислительно трудны и, в основном, основаны на использовании <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">Markov Chain Monte Carlo</a>, который плохо масштабируем. Поэтому для обучения генеративных моделей нужен был метод, основанный на таких масштабируемых техниках, как <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent (SGD)</a> и <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>. Один из таких методов &mdash; Generative Adversarial Networks (GAN). Впервые GANы были предложены <a href="https://arxiv.org/pdf/1406.2661.pdf">в этой</a> статье в 2014 году. Высокоуровнево эта модель может быть описана, как две подмодели, которые соревнуются друг с другом, и одна из этих моделей (генератор), пытается научиться в некотором смысле обманывать вторую (дискриминатор). Для этого генератор генерирует случайные объекты, а дискриминатор пытается отличить эти сгенерированные объекты от настоящих объектов из тренировочной выборки. В процессе обучения генератор генерирует все более похожие на выборку объекты и дискриминатору становится все сложнее отличить их от настоящих. Таким образом, генератор превращается в генеративную модель, которая генерирует объекты из некого сложного распределения, например, из распределения фотографий человеческих лиц.</p>

<h2>Модель</h2>

<p>Для начала введем необходимую терминологию. Через $X$ мы будем обозначать некоторое пространство объектов. Например, картинки $64\times 64\times 3$ пикселя. На некотором вероятностном пространстве $\Omega$ задана векторная случайная величина $x : \Omega \to X$ с распределением вероятностей, имеющим плотность $p(x)$ такую, что подмножество пространства $X$, на котором $p(x)$ принимает ненулевые значения &mdash; это, например, фотографии человеческих лиц. Нам дана случайная i.i.d. выборка фотографий лиц для величины ${x_i,  i \in [1, N], x_i \sim p(x)}$. Дополнительно определим вспомогательное пространство $Z=R^n$ и случайную величину $z:\Omega \to Z$ с распределением вероятностей, имеющим плотность $q(z)$. $D:X \to (0,1)$ &mdash; функция-дискриминатор. Эта функция принимает на вход объект $x \in X$ (в нашем примере &mdash; картинку соответствующего размера) и возвращает вероятность того, что входная картинка является фотографией человеческого лица. $G: Z \to X$ &mdash; функция-генератор. Она принимает значение $z \in Z$ и выдает объект пространства $X$, то есть, в нашем случае, картинку.</p>

<p>Предположим, что у нас уже есть идеальный дискриминатор $D$. Для любого примера $x$ он выдает истинную вероятность принадлежности этого примера заданному подмножеству $X$, из которого получена выборка ${x_i}$. Переформулируя задачу обмана дискриминатора, на вероятностном языке мы получаем, что необходимо максимизировать вероятность, выдаваемую идеальным дискриминатором на сгенерированных примерах. Таким образом оптимальный генератор находится как $G^{*}=\arg \max_G E_{z \sim q(x)} D_k\left(G\left(z\right)\right)$. Так как $\log(x)$ &mdash; монотонно возрастающая функция и не меняет положения экстремумов аргумента, эту формулу можно переписать в виде $G^{*}=\arg \max_G E_{z \sim q(x)} \log D_k\left(G\left(z\right)\right)$, что будет удобно в дальнейшем.</p>

<p>В реальности обычно идеального дискриминатора нет и его надо найти. Так как задача дискриминатора &mdash; предоставлять сигнал для обучения генератора, вместо идеального дискриминатора достаточно взять дискриминатор, идеально отделяющий настоящие примеры от сгенерированных текущим генератором, т.е. идеальный только на подмножестве $X$, из которого генерируются примеры текущим генератором. Эту задачу можно переформулировать, как поиск такой функции $D$, которая максимизирует вероятность правильной классификации примеров как настоящих или сгенерированных. Это называется задачей бинарной классификации и в данном случае мы имеем бесконечную обучающую выборку: конечное число настоящих примеров и потенциально бесконечное число сгенерированных примеров. У каждого примера есть метка: настоящий он или сгенерированный. В <a href="/ru/posts/2017/10/30/generative-modeling-with-deep-learning.html">первой статье</a> было описано решение задачи классификации с помощью метода максимального правдоподобия. Давайте распишем его для нашего случая.</p>

<p>Итак, наша выборка $S={(x, 1), x \sim p(x)} \cup {(G(z), 0), z \sim q(z) }$. Определим плотность распределения $f(\xi|\eta=1)=D(\xi), f(\xi|\eta=0)=1−D(\xi)$, тогда $f(\xi|\eta)$ &mdash; это переформулировка дискриминатора $D$, выдающего вероятность класса $1$ (настоящий пример) в виде распределения на классах ${0, 1}$. Так как $D(\xi) \in (0, 1)$, это определение задает корректную плотность вероятности. Тогда оптимальный дискриминатор можно найти как:
\begin{equation}
    D^{*}=f^{*}(\xi|\eta)=\arg \max_{f} f(\xi_1,...|\eta_1,...)=\arg \max_{f} \prod_i f(\xi_i|\eta_i)
\end{equation}
Сгруппируем множители для $\eta_i=0$ и $\eta_i=1$:</p>

<p>\begin{equation}
D^{*}=\arg \max_{f} \prod_{i, \eta=1} f\left(\xi_i|\eta_i=1\right) \prod_{i, \eta=0} f\left(\xi_i|\eta_i=0\right)=
\end{equation}
\begin{equation}
=\arg \max_{D} \prod_{x_i \sim p(x)} D\left(x_i \right) \prod_{z_i \sim q(z)} \left(1−D\left(G\left(z_i\right)\right)\right)=
\end{equation}
\begin{equation}
=\arg \max_{D} \sum_{x_i \sim p(x)} \log D\left(x_i\right) + \sum_{z_i \sim q(z)} \log \left(1−D\left(G\left(z_i\right)\right)\right)
\end{equation}</p>

<p>И при стремлении размера выборки в бесконечность, получаем:
\begin{equation}
D^{*}=\arg \max_{D}E_{x_i \sim p(x)} \log D\left(x_i\right) + E_{z_i \sim q(z)} \log \left(1−D\left(G\left(z_i\right)\right)\right)
\end{equation}</p>

<p>Итого, получаем следующий итерационный процесс:</p>

<ol>
<li>Устанавливаем произвольный начальный $G_0(z)$.</li>
<li>Начинается $k$-я итерация, $k = 1...K$.</li>
<li>Ищем оптимальный для текущего генератора дискриминатор:
$D_k=\arg \max_{D}E_{x_i \sim p(x)} \log D\left(x_i\right) + E_{z_i \sim q(z)} \log \left(1−D\left(G_{k−1}\left(z_i\right)\right)\right)$</li>
<li>Улучшаем генератор, используя оптимальный дискриминатор: $G_k=\arg \max_G E_{z \sim q(x)} \log D_k\left(G\left(z\right)\right)$. Важно находиться в окрестности текущего генератора. Если отойти далеко от текущего генератора, то дискриминатор перестанет быть оптимальным и алгоритм перестанет быть верным.</li>
<li>Задача обучения генератора считается решенной, когда $D_k(x)=1/2$ для любого $x$. Если процесс не сошелся, то переходим на следующую итерацию в пункт (2).</li>
</ol>

<p>В оригинальной статье этот алгоритм суммаризируется в одну формулу, задающую в некотором смысле минимакс-игру между дискриминатором и генератором:
\begin{equation}
  \min_G \max_D L(D, G) = E_{x \sim p(x)} \log D(x) + E_{z \sim q(z)} \log \left(1−D\left(G\left(z\right)\right)\right)
\end{equation}</p>

<p>Обе функции $D, G$ могут быть представлены в виде нейросетей: $D(x) = D(x, \theta_1), G(z)=G(z, \theta_2)$, после чего задача поиска оптимальных функций сводится к задаче оптимизации по параметрам и ее можно решать с помощью традиционных методов: backpropagation и SGD. Дополнительно, так как нейросеть &mdash; это универсальный аппроксиматор функций, $G(z, \theta_2)$ может приблизить произвольное распределение вероятностей, что снимает вопрос выбора распределения $q(z)$. Это может быть любое непрерывное распределение в некоторых разумных рамках. Например, $Uniform(−1,1)$ или $N(0, 1)$. Корректность этого алгоритма и сходимость $G(z)$ к $p(x)$ при достаточно общих предположениях доказана в оригинальной статье.</p>

<h2>Нахождение параметров нормального распределения</h2>

<p>С математикой мы разобрались, давайте теперь посмотрим, как это работает. Допустим, $X=R$, т.е. решаем одномерную задачу. $p(x)=N(\mu, \sigma), q(z)=N(0, 1)$. Давайте использовать линейный генератор $G(z, \theta)=a z + b$, где $\theta={a, b}$. Дискриминатор будет полносвязной трехслойной нейронной сетью с бинарным классификатором на конце. Решением этой задачи является $G(z, \mu, \sigma)=\mu z + \sigma$, то есть, $a=\mu, b=\sigma$. Попробуем теперь запрограммировать численное решение этой задачи с помощью Tensorflow. Полный код можно найти <a href="https://github.com/Monnoroch/generative/tree/master/gan_model_data">тут</a>, в статье же освещены только ключевые моменты.</p>

<p>Первое, что нужно задать, это входную выборку: $p(x)=N(\mu, \sigma)$. Так как обучение идет на минибатчах, мы будем за раз генерировать вектор чисел. Дополнительно, выборка параметризуется средним и стандартным отклонением.</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">data_batch</span><span class="p">(</span><span class="n">hparams</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Input data are just samples from N(mean, stddev).</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span>
    <span class="p">[</span><span class="n">hparams</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">hparams</span><span class="o">.</span><span class="n">input_mean</span><span class="p">,</span> <span class="n">hparams</span><span class="o">.</span><span class="n">input_stddev</span><span class="p">)</span>
</code></pre></div>
<p>Теперь зададим случайные входы для генератора $q(z)=N(0,1)$:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">generator_input</span><span class="p">(</span><span class="n">hparams</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Generator input data are just samples from N(0, 1).</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">hparams</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
</code></pre></div>
<p>Определим генератор. Возьмем абсолютное значение второго параметра для придания ему смысла стандартного отклонения:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">generator</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
  <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.</span><span class="p">))</span>
  <span class="n">stddev</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
  <span class="k">return</span> <span class="nb">input</span> <span class="o">*</span> <span class="n">stddev</span> <span class="o">+</span> <span class="n">mean</span>
</code></pre></div>
<p>Создадим вектор реальных примеров:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="n">real_input</span> <span class="o">=</span> <span class="n">data_batch</span><span class="p">(</span><span class="n">hparams</span><span class="p">)</span>
</code></pre></div>
<p>И вектор сгенерированных примеров:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="n">generator_input</span> <span class="o">=</span> <span class="n">generator_input</span><span class="p">(</span><span class="n">hparams</span><span class="p">)</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">generator_input</span><span class="p">)</span>
</code></pre></div>
<p>Теперь прогоним все примеры через дискриминатор. Тут важно помнить о том, что мы хотим не два разных дискриминатора, а один, потому Tensorflow нужно попросить использовать одни и те же параметры для обоих входов:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;discriminator&quot;</span><span class="p">):</span>
  <span class="n">real_ratings</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">real_input</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;discriminator&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
  <span class="n">generated_ratings</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span>
</code></pre></div>
<p>Функция потерь на реальных примерах &mdash; это кросс-энтропия между единицей (ожидаемым ответом дискриминатора на реальных примерах) и оценками дискриминатора:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="n">loss_real</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_ratings</span><span class="p">),</span>
    <span class="n">logits</span><span class="o">=</span><span class="n">real_ratings</span><span class="p">))</span>
</code></pre></div>
<p>Функция потерь на поддельных примерах &mdash; это кросс-энтропия между нулем (ожидаемым ответом дискриминатора на поддельных примерах) и оценками дискриминатора:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="n">loss_generated</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">generated_ratings</span><span class="p">),</span>
    <span class="n">logits</span><span class="o">=</span><span class="n">generated_ratings</span><span class="p">))</span>
</code></pre></div>
<p>Функция потерь дискриминатора &mdash; это сумма потерь на реальных примерах и на поддельных примерах:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="n">discriminator_loss</span> <span class="o">=</span> <span class="n">loss_generated</span> <span class="o">+</span> <span class="n">loss_real</span>
</code></pre></div>
<p>Функция потерь генератора &mdash; это кросс-энтропия между единицей (желаемым ошибочным ответом дискриминатора на поддельных примерах) и оценками этих поддельных примеров дискриминатором:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="n">generator_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">generated_ratings</span><span class="p">),</span>
    <span class="n">logits</span><span class="o">=</span><span class="n">generated_ratings</span><span class="p">))</span>
</code></pre></div>
<p>К функции потерь дискриминатора опционально добавляется L2-регуляризация.</p>

<p>Обучение модели сводится к поочередному обучению дискриминатора и генератора в цикле до сходимости:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">max_steps</span><span class="p">):</span>
  <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">discriminator_train</span><span class="p">)</span>
  <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">generator_train</span><span class="p">)</span>
</code></pre></div>
<p>Ниже приведены графики для четырех моделей дискриминатора:</p>

<ul>
<li>трехслойная нейронная сеть.</li>
<li>трехслойная нейронная сеть с L2-регуляризацией.</li>
<li>трехслойная нейронная сеть с dropout-регуляризацией.</li>
<li>трехслойная нейронная сеть с L2- и dropout-регуляризацией.</li>
</ul>

<p><center> <table class="image">
    <caption align="bottom">Рис. 1. Вероятность классификации дискриминатором реального примера как реального.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/p_real_on_real.png" alt="Рис. 1. Вероятность классификации дискриминатором реального примера как реального." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 2. Вероятность классификации дискриминатором сгенерированного примера как реального.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/p_real_on_fake.png" alt="Рис. 2. Вероятность классификации дискриминатором сгенерированного примера как реального." width="520"/></td></tr>
</table> </center></p>

<p>Все четыре модели достаточно быстро сходятся к тому, что дискриминатор выдает $1/2$ на всех входах. Из-за простоты задачи, которую решает генератор, между моделями почти нет разницы. Из графиков видно, что среднее и стандартное отклонение довольно быстро сходятся к значениям из распределения данных:</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 3. Среднее сгенерированных распределений.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/g_mean.png" alt="Рис. 3. Среднее сгенерированных распределений." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 4. Среднеквадратичное отклонение сгенерированных распределений.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/g_stddev.png" alt="Рис. 4. Среднеквадратичное отклонение сгенерированных распределений." width="520"/></td></tr>
</table> </center></p>

<p>Ниже приведены распределения настоящих и сгенерированных примеров в процессе обучения. Видно, что сгенерированные примеры к концу обучения практически не отличимы от настоящих (они отличимы на графиках потому, что Tensorboard выбрал разные масштабы, но, если посмотреть на значения, то они одинаковые).</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 5. Распределение реальных данных. Не меняется во времени. Шаг обучения отложен на вертикальной оси.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/real_data_base_train.png" alt="Рис. 5. Распределение реальных данных. Не меняется во времени. Шаг обучения отложен на вертикальной оси." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom"></caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_base_train.png" alt="" width="520"/></td></tr>
</table> </center></p>

<p><center>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_l2_reg_train_a.png" width="170"/>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_dropuot_l2_reg_train_a.png" width="170"/>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_dropuot_train_a.png" width="170"/>
</center>
<center>
Рис. 6. Распределение реальных данных. Не меняется во времени. Шаг обучения отложен на вертикальной оси.
</center></p>

<p>Давайте посмотрим на процесс обучения модели:</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 7. Визуализация процесса обучения модели. Неподвижная гауссиана &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/intro.gif" alt="Рис. 7. Визуализация процесса обучения модели. Неподвижная гауссиана &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим." width="520"/></td></tr>
</table> </center></p>

<p>Видно, что дискриминатор в начале обучения очень хорошо разделяет данные, но распределение генерируемых примеров очень быстро буквально “подползает” к распределению настоящих примеров. В конце концов, генератор настолько хорошо приближает данные, что дискриминатор становится константой $1/2$ и задача сходится.</p>

<h2>Приближение смеси нормальных распределений I</h2>

<p>Попробуем заменить $p(x)=N(\mu,\sigma)$ на $p(x)=Mixture(N(\mu_1, \sigma_1), N(\mu_2, \sigma_2))$, тем самым смоделировав мультимодальное распределение исходных данных. Для этой модели нужно изменить только код генерации реальных примеров. Вместо возвращения нормально распределенной случайной величины мы возвращаем смесь нескольких:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">data_batch</span><span class="p">(</span><span class="n">hparams</span><span class="p">):</span>
  <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">input_mean</span><span class="p">)</span>
  <span class="n">componens</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
      <span class="n">componens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span>
          <span class="n">loc</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">input_mean</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
          <span class="n">scale</span><span class="o">=</span><span class="n">hparams</span><span class="o">.</span><span class="n">input_stddev</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Mixture</span><span class="p">(</span>
    <span class="n">cat</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span>
      <span class="n">probs</span><span class="o">=</span><span class="p">[</span><span class="mf">1.</span><span class="o">/</span><span class="n">count</span><span class="p">]</span> <span class="o">*</span> <span class="n">count</span><span class="p">),</span>
    <span class="n">components</span><span class="o">=</span><span class="n">componens</span><span class="p">)</span>
      <span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="p">[</span><span class="n">hparams</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</code></pre></div>
<p>Ниже приведены графики для тех же самых моделей, что и в прошлом эксперименте, но для данных с двумя модами:</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 8. Вероятность классификации дискриминатором реального примера как реального.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/p_real_on_real_2_models.png" alt="Рис. 8. Вероятность классификации дискриминатором реального примера как реального." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 9. Вероятность классификации дискриминатором сгенерированного примера как реального.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/p_real_on_fake_2_models.png" alt="Рис. 9. Вероятность классификации дискриминатором сгенерированного примера как реального." width="520"/></td></tr>
</table> </center></p>

<p>Интересно заметить, что регуляризованные модели показывают себя существенно лучше нерегуляризованных. Однако, независимо от модели видно, что теперь генератору не удается так хорошо обмануть дискриминатор. Давайте поймем, почему так получилось.</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 10. Среднее сгенерированных распределений.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/g_mean_2.png" alt="Рис. 10. Среднее сгенерированных распределений." width="520"/></td></tr>
</table> </center>
<center> <table class="image">
    <caption align="bottom">Рис. 11. Среднеквадратичное отклонение сгенерированных распределений.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/g_stddev_2.png" alt="Рис. 11. Среднеквадратичное отклонение сгенерированных распределений." width="520"/></td></tr>
</table> </center></p>

<p>Как и в первом эксперименте, генератор приближает данные нормальным распределением. Причина снижения качества в том, что теперь данные нельзя точно приблизить нормальным распределением, ведь они сэмплируются из смеси двух нормальных. Моды смеси симметричны относительно нуля, и видно, что все четыре модели приближают данные нормальным распределением с центром рядом с нулем и достаточно большой дисперсией. Давайте посмотрим на распределения настоящих и поддельных примеров, чтобы понять, что происходит:</p>

<p><center> <table class="image">
    <caption align="bottom">Рис 12. Распределение реальных данных. Не меняется во времени. Шаг обучения отложен на вертикальной оси.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/real_data_base_train_2.png" alt="Рис 12. Распределение реальных данных. Не меняется во времени. Шаг обучения отложен на вертикальной оси." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom"></caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_base_train_2.png" alt="" width="520"/></td></tr>
</table> </center>
<center>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_l2_reg_train_2.png" width="170"/>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_dropout_l2_reg_train_2.png" width="170"/>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_dropout_train_2.png" width="170"/>
</center>
<center>
Рис 13. Распределения сгенерированных данных от четырех моделей. Шаг обучения отложен на вертикальной оси.
</center></p>

<p>Так проходит процесс обучения модели:</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 14. Визуализация процесса обучения модели. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/training.gif" alt="Рис. 14. Визуализация процесса обучения модели. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим." width="520"/></td></tr>
</table> </center></p>

<p>Эта анимация подробно показывает изученный выше случай. Генератор, не обладая достаточной экспрессивностью и имея возможность приближать данные только гауссианой, расплывается в широкую гауссиану, пытаясь охватить обе моды распределения данных. В результате генератор достоверно обманывает дискриминатор только в местах, где площади под кривыми генератора и исходных данных близки, то есть в районе пересечений этих кривых.</p>

<p>Однако, это не единственный возможный случай. Давайте подвинем правую моду еще немного правее, чтобы начальное приближение генератора ее не захватывало.</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 15. Визуализация процесса обучения модели. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим.
</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/training_2.gif" alt="Рис. 15. Визуализация процесса обучения модели. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим.
" width="520"/></td></tr>
</table> </center></p>

<p>Видно, что в этом случае генератору выгоднее всего попытаться приблизить левую моду распределения. После того, как это происходит, генератор пытается предпринять попытки захватить и левую моду. Это выглядит, как осцилляции стандартного отклонения генератора во второй половине анимации. Но все эти попытки проваливаются, так как дискриминатор как-бы “запирает” генератор и для захвата левой моды ему необходимо преодолеть барьер из высокой функции потерь, чего он не может сделать из-за недостаточно большой скорости обучения. Данный эффект называется коллапсированием моды.</p>

<p>На двух вышеописанных примерах мы увидели два типа проблем, возникающих в том случае, если генератор недостаточно мощный, чтобы выразить исходное распределение данных: усреднение мод, когда генератор приближает все распределение, но везде достаточно плохо; и коллапсирование моды, когда генератор выучивает подмножество мод, а те, которые он не выучил, никак на него не влияют.</p>

<p>Помимо того, что обе этих проблемы приводят к несходимости дискриминатора к $1/2$, они также приводят к снижению качества генеративной модели. Первая проблема приводит к тому, что генератор выдает примеры “между” мод, которых не должно быть, вторая проблема приводит к тому, что генератор выдает примеры только из некоторых мод, тем самым снижая богатство исходного распределения данных.</p>

<h2>Приближение смеси нормальных распределений II</h2>

<p>Причиной того, что в предыдущем разделе не получилось до конца обмануть дискриминатор была тривиальность генератора, который просто делал линейное преобразование. Попробуем теперь в качестве генератора использовать полносвязную трехслойную нейронную сеть:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span></span><span class="k">def</span> <span class="nf">generator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
  <span class="c1"># Первый полносвязный слой с 256 фичами.</span>
  <span class="n">input_size</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="n">features</span> <span class="o">=</span> <span class="mi">256</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
    <span class="s2">&quot;weights_1&quot;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span>
      <span class="p">[</span><span class="n">input_size</span><span class="p">,</span> <span class="n">features</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
  <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
    <span class="s2">&quot;biases_1&quot;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">features</span><span class="p">]))</span>
  <span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span><span class="p">)</span>

  <span class="c1"># Второй полносвязный слой с 256 фичами.</span>
  <span class="n">features</span> <span class="o">=</span> <span class="mi">256</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
    <span class="s2">&quot;weights_2&quot;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span>
      <span class="p">[</span><span class="n">input_size</span><span class="p">,</span> <span class="n">features</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
  <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
    <span class="s2">&quot;biases_2&quot;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">features</span><span class="p">]))</span>
  <span class="n">hidden_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span><span class="p">)</span>

  <span class="c1"># Последний линейный слой, генерирующий пример.</span>
  <span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
    <span class="s2">&quot;weights_out&quot;</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span>
      <span class="p">[</span><span class="n">features</span><span class="p">,</span> <span class="n">output_size</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
  <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
    <span class="s2">&quot;biases_out&quot;</span><span class="p">,</span>
     <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">output_size</span><span class="p">]))</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_layer</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
</code></pre></div>
<p>Давайте посмотрим на графики обучения.</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 16. Вероятность классификации дискриминатором реального примера как реального.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/p_real_on_real_2.png" alt="Рис. 16. Вероятность классификации дискриминатором реального примера как реального." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 17. Вероятность классификации дискриминатором сгенерированного примера как реального.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/p_real_on_fake_2.png" alt="Рис. 17. Вероятность классификации дискриминатором сгенерированного примера как реального." width="520"/></td></tr>
</table> </center></p>

<p>Видно, что из-за большого количества параметров обучение стало гораздо более шумным. Дискриминаторы всех моделей сходятся к результату около $1/2$, но ведут себя нестабильно вокруг этой точки. Давайте посмотрим на форму генератора.</p>

<p><center> <table class="image">
    <caption align="bottom">Рис 18. Распределение реальных данных. Не меняется во времени. Шаг обучения отложен на вертикальной оси.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/real_data_base_train_3.png" alt="Рис 18. Распределение реальных данных. Не меняется во времени. Шаг обучения отложен на вертикальной оси." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom"></caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_dropout_l2_reg_train_3.png" alt="" width="520"/></td></tr>
</table> </center>
<center>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_l2_reg_train_3.png" width="170"/>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_base_train_3.png" width="170"/>
<img src="/images/posts/2018-04-03-generative-adversarial-networks/fake_data_dropout_train_3.png" width="170"/>
</center>
<center>
Рис 19. Распределения сгенерированных данных от четырех моделей. Шаг обучения отложен на вертикальной оси.
</center></p>

<p>Видно, что распределение генератора хоть не совпадает с распределением данных, но достаточно сильно похоже на него. Самая регуляризованная модель опять показала себя лучше всех. Видно, что она выучила две моды, примерно совпадающие с модами распределения данных. Размеры пиков тоже не очень точно, но приближают распределение данных. Таким образом, нейросетевой генератор способен выучить мультимодальное распределение данных.</p>

<p>Так проходит процесс обучения модели:</p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 20. Визуализация процесса обучения модели с близкими модами. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/training_3.gif" alt="Рис. 20. Визуализация процесса обучения модели с близкими модами. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим." width="520"/></td></tr>
</table> </center></p>

<p><center> <table class="image">
    <caption align="bottom">Рис. 21. Визуализация процесса обучения модели с далекими модами. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим.</caption>
    <tr><td><img src="/images/posts/2018-04-03-generative-adversarial-networks/training_4.gif" alt="Рис. 21. Визуализация процесса обучения модели с далекими модами. Неподвижная смесь гауссиан &mdash; плотность распределения реальных данных, движущаяся гауссиана &mdash; плотность распределения генерируемых примеров, синяя кривая &mdash; результат работы дискриминатора, т.е. вероятность примера быть настоящим." width="520"/></td></tr>
</table> </center></p>

<p>Эти две анимации показывают обучение на распределениях данных из предыдущего раздела. Из этих анимаций видно, что при использовании достаточно большого генератора с множеством параметров он, пусть и довольно грубо, но способен приближать мультимодальное распределение, тем самым косвенно подтверждая то, что проблемы из предыдущего раздела возникают из-за недостаточно сложного генератора. Дискриминаторы на этих анимациях гораздо более шумные, чем в разделе про нахождение параметров нормального распределения, но, тем не менее, к концу обучения начинают напоминать зашумленную горизонтальную прямую $D(x)=1/2$.</p>

<h2>Итоги</h2>

<p>GAN &mdash; это модель, для приближения произвольного распределения только с помощью сэмплирования из этого распределения. В этой статье мы посмотрели в деталях, как модель работает на тривиальном примере поиска параметров нормального распределения и на более сложном примере аппроксимации бимодального распределения нейронной сетью. Обе задачи были с хорошей точностью решены, для чего потребовалось только использовать достаточно сложную модель генератора. В следующей статье мы перейдем от этих модельных примеров к реальным примерам генерации сэмплов из сложных распределений на примере распределения изображений.</p>

<h2>Благодарности</h2>

<p>Спасибо <a href="https://www.linkedin.com/in/olga-talanova-b319b761/">Olga Talanova</a> и <a href="https://www.linkedin.com/in/ruslan-login-68bb2676/">Ruslan Login</a> за ревью текста. Спасибо <a href="https://www.linkedin.com/in/ruslan-login-68bb2676/">Ruslan Login</a> за помощь в подготовке изображений и анимаций. Спасибо <a href="https://github.com/andrewtar">Andrei Tarashkevich</a> за помощь с версткой этой статьи.</p>


</div>

<div class="pagination">
  
  
    <a href="/ru/posts/2018/03/28/advanced-android-testing.html" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>
    <footer>
        <span>
            &copy; <time datetime="2018-10-27 19:30:09 +0000">2018</time> You can find me on <a href="https://github.com/Monnoroch">GitHub</a>.
        </span>
    </footer>
    <script src="/scripts/responsive.js" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']]
            }
        });
    </script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
